---
layout: standard
title: Bogdan Ivanyuk-Skulskyi
---
<div>
  <h1 class="title">Hi there, I'm Bogdan Ivanyuk-Skulskyi</h1>

  <img class="photo" src="/assets/profile.png" alt="Bogdan photo" />

  <div class="content-col">
    <p>
      <!-- I am a first-year Ph.D. student at CRIStAL, University of Lille and Cyclope.ai (Vinci Autoroutes),
      advised by <a href="https://scholar.google.com/citations?user=jfjZfnoAAAAJ&hl">prof. Nadiya Shvai</a>,
      <a href="https://scholar.google.com/citations?user=iCUYHs4AAAAJ&hl">Amir Nakib</a>, and
      <a href="https://scholar.google.com/citations?user=hoQmzocAAAAJ&hl">El-ghazali Talbi</a>.
      Prior to joining CRIStAL,  -->

      I am a machine learning engineer at Cyclop.ai (Vinci), working on security systems for road 
      infrastructure (tunnels, bridges, etc.) and autonomous vehicles.
      <br>
      <br>

      I obtained my Bachelor's degree in 2020 and completed my Master's degree in 2022 at the National 
      University of Kyiv-Mohyla Academy. Throughout my academic journey, I had the privilege of working 
      under the guidance of 
      <a href="https://scholar.google.com/citations?user=DD1d1b4AAAAJ&hl">Prof. Galyna Kriukova</a>,
      <a href="https://scholar.google.com/citations?user=VZd6me0AAAAJ&hl">Andrii Dmytryshyn</a>, and
      <a href="https://scholar.google.com/citations?user=jfjZfnoAAAAJ&hl">Nadiya Shvai</a>.
      <br>
      <br>
      During my Master's program, I had an internship at Samsung Research, specifically within the Integent Security Lab, 
      focusing on voice security applications. Additionally, I did an internship at the University of Toronto, where 
      I worked under the supervision of 
      <a href="https://kite-uhn.com/scientist/brokoslaw-laschowski">Dr. Brokoslaw Laschowski</a>, and
      <a href="https://ot.utoronto.ca/about/core-faculty/alex-mihailidis/">Dr. Alex Mihailidis</a> on video
      classification model for exoskeleton control.
      <br>
      <br>
      My interests primarily include video processing, anomaly and out-of-distribution data detection, reinforcement learning, and robotics.
    </p>

    <br>
    <h3 class="title">Publications:</h3>
    <small>
      <b style="font-size: 120%;">2023:</b>
      <ul>
        <li>
          <b>StairNet: Visual recognition of stairs for human-robot locomotion</b>
          <br>
          A G Kurbis, D Kuzmenko, <u>B Ivaniuk-Skulskyi</u>, A Mihailidis, B Laschowski
          <br>
          <i>Submitted to BioMedical Engineering OnLine</i><br />
          <a href="https://arxiv.org/abs/2310.20666">[pre-print]</a>
          <br />
          Comparison of state estimation models of the walking environment in robotic prosthetic legs and exoskeletons.
          <br />
        </li>
      </ul>
      
      <ul>
        <li>
          <b>Sequential Image Classification of Human-Robot Walking Environments using Temporal Neural Networks</b>
          <br>
          <u>B Ivaniuk-Skulskyi</u>, A G Kurbis, A Mihailidis, B Laschowski
          <br>
          <i><a href="https://projects.iq.harvard.edu/visionwearablerobotics/about">In IEEE ICRA 2023</a>, Computer
            vision for Wearable Robotics workshop; KITE/UHN ICAIR 2023</i><br />
          <a href="assets/papers/Ivaniuk-Skulsky_ICAIR2023.pdf">[ICAIR Poster]</a>
          <a href="assets/papers/Ivanyuk-Skulsky_ICRA2023.pdf">[ICRA Abstract]</a>
          <a href="https://www.biorxiv.org/content/10.1101/2023.11.10.566555v1">[pre-print]</a>
          <a href="https://github.com/KyloRen1/Sequence-Classification-of-Human-Robot-Walking">[Code]</a><br />
          State estimation model of the walking environment in robotic prosthetic legs and exoskeletons,
          focusing on dynamic human-robot walking dynamics rather than static image classification. <br />

          <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
            <img src="assets/papers/Ivaniuk-Skulsky_ICAIR2023.pdf" class="images" width="320" />
          </div>
        </li>
      </ul>

      <b style="font-size: 120%;">2020:</b>
      <ul>
        <li>
          <b>Geometric Properties of Adversarial Images</b>
          <br>
          <u>B Ivaniuk-Skulskyi</u>, G Kriukova, A Dmytryshyn
          <br>
          <i>In IEEE DSMP 2020</i><br />
          <a href="https://ieeexplore.ieee.org/document/9204251">[Paper]</a>
          <a href="https://github.com/KyloRen1/Geometric-properties-of-adversarial-images">[Code]</a><br />
          Linear algebra-based approach to detect adversarial images, addressing the challenge of identifying slight
          modifications that mislead machine learning models' predictions, and supporting the method with theoretical
          explanation and numerical experiments.

          <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
            <img class="images" src="/assets/papers/generated_images.png" width="320" alt="Megaverse gif" />
          </div>
        </li>
      </ul>
    </small>
    <br>
    <br>


    <h3 class="title">Selected open-source projects:</h3>
    <ul>
      <li>
        <b>Tower Defence RL agent</b>
        <a href="https://github.com/KyloRen1/TowerDefenceRLagent">[Code]</a><br>
        An implementation of a classical Tower Defence game, which allows you to play it on your own, 
        and it also includes a gym-like environment for training RL agents.
        <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
          <img class="images" src="/assets/projects/tower_defence.gif" width="350" alt="Surviv.io rl agent" />
        </div>
      </li>
      <li>
        <b>Raspberry Pi car</b>
        <a href="https://github.com/KyloRen1/RaspberryPi-car">[Code]</a><br>
        Building a Raspberry Pi car, from putting it together to testing and adding remote control features.
        <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
          <img src="assets/projects/rasp_pi/car.gif" alt="GIF 1" width="30%">
          <img src="assets/projects/rasp_pi/test.gif" alt="GIF 2" width="53%">
        </div>
      </li>
      <li>
        <b>UA-datasets</b>
        <a href="https://fido-ai.github.io/ua-datasets/">[Documentation]</a>
        <a href="https://github.com/fido-ai/ua-datasets">[Code]</a>
        <a href="https://huggingface.co/FIdo-AI">[Hugging Face Hub]</a><br>
        Collection of datasets for the Ukrainian language. These datasets include text classification, 
        question answering, and token classification tasks. They are neatly organized and provided within 
        a Python package and also accessible on the Hugging Face Hub for easy use and integration into your NLP projects.
      </li>
      <li>
        <b>Surviv.io game bot</b>
        <a href="https://github.com/Laggg/ml-bots-surviv.io">[Code]</a> <br>
        Reinforcement Learning Agent for the Online Multiplayer Battle Royale Game surviv.io.
        <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
          <img class="images" src="/assets/projects/surviv.gif" width="350" alt="Surviv.io rl agent" />
        </div>
      </li>
      <li>
        <b>Quora Insincere Questions Classification (Kaggle)</b>
        <a href="https://github.com/KyloRen1/Kaggle-Quora-Insincere-Questions-Classification">[Code]</a><br>
        NLP competition for insincere questions classification (silver medal, top 2% solution).
      </li>
      <li>
        <b>Exploring cross-lingual abilities of Multilingual BERT</b>
        <a href="https://github.com/KyloRen1/CS224N-NLP-DeepPavlov">[Code]</a><br>
        I studied M-BERT's transfer learning for classification tasks, moving from English to Russian test sets, 
        and compared the results to RuBERT. I also explored M-BERT's transfer learning for Boolean Questions, 
        fine-tuning on English BoolQ and NLI datasets, then validating on a Russian test set and comparing the 
        outcomes to RuBERT.
      </li>
    </ul>

    <br />
    <p>Let's <a href="mailto:ivanyuk.bogdan1999@gmail.com">get in touch!</a>
  </div>
</div>
