---
layout: standard
title: Bogdan Ivanyuk-Skulskyi - Reviews
---

<div>
    <h1><span style="font-size: 0.85em; font-weight: bold;">Paper review: NN-sort: Neural Network based Data Distribution-aware Sorting</span></h1>
    <p><span style="background-color: #f2f2f2; padding: 2px 4px; border-radius: 4px; font-weight: bold;">Date</span>: 2021-09-03</p>
    <p><span style="background-color: #f2f2f2; padding: 2px 4px; border-radius: 4px; font-weight: bold;">Tags</span>: sorting, neural networks</p>

    <h2>NN-sort Algorithm: Sorting with Neural Network</h2>
    <p>The authors propose a new sorting algorithm called "NN-sort", which leverages the neural network model to learn the data distribution and afterward uses it to map disordered data elements into ordered ones. The complexity of the algorithm is O(N log N) in theory, it can run in near-linear time in most of the cases observed.</p>

    <h2>NN-SORT Design</h2>
    <p>Sorting is performed in multiple rounds: on each round, the model puts the input data into roughly sorted order. If conflicts occur, all the non-conflicts data elements are organized in an array that is roughly ordered, while conflicts data will be put in a conflicting array, which is used as an input of the next iteration. Such iterations continue until the size of the conflicting array is smaller than a threshold. Then, the conflicting array is sorted by classic sorting algorithms, like Quick Sort. In the end, all the roughly ordered arrays and strictly sorted conflicting arrays are merged.</p>
    <p><img src="/assets/reviews/nn_sort/Figure1.png" alt="NN-SORT Design"/></p>
    <p><img src="/assets/reviews/nn_sort/algorithm1.png" alt="Algorithm 1" width="300"/></p>
    <p><img src="/assets/reviews/nn_sort/algorithm2.png" alt="Algorithm 2" width="300"/></p>

    <h2>NN-model for NN-SORT</h2>
    <p>The neural network is composed of 3 hidden layers. The first layer has 32 neurons, while the second layer has 8, the third layer has 4 neurons. Such simple models can be efficiently trained using SGD and they are not so susceptible to overfitting.</p>
    <p>In order to avoid the impact of outliers, the model is trained using Huber loss:</p>
    <p><img src="/assets/reviews/nn_sort/eq1.png" alt="Huber Loss Equation"/></p>

    <h2>Model Analysis</h2>

    <h3>Best Case</h3>
    <p>If \(n > 1\), it needs \(\theta n\) operations to sort all the data elements and one pass (\(n\) operations) to remove any empty positions at the output.</p>
    <p><img align="center" src="/assets/reviews/nn_sort/best_case.png" alt="Best Case"/></p>

    <h3>General Case</h3>
    <p>Where \(\sigma\) - collision rate per iteration, \(\theta\) - the number of operations required for the data points to pass through the neural network, \(e\) - number of data points that were misordered in the \(i\)-th iteration.<br/>
    The whole sorting process can be divided into 2 parts:</p>
    <ol>
        <li>Generating several roughly ordered arrays and one ordered conflicting array</li>
        <li>Merging all the roughly ordered arrays</li>
    </ol>
    <p><img align="center" src="/assets/reviews/nn_sort/general_case.png" alt="General Case"/></p>

    <h3>Worst Case</h3>
    <p>The sorting process is then divided into 3 parts:</p>
    <ol>
        <li>Feeding data elements into the model for \(\epsilon\) times</li>
        <li>Sorting all the conflicting data points</li>
        <li>Correcting the out-of-order data elements and merging all the sorted arrays</li>
    </ol>
    <p><img align="center" src="/assets/reviews/nn_sort/worst_case.png" alt="Worst Case"/></p>

    <h3>Evaluation</h3>
    <p><img src="/assets/reviews/nn_sort/figure4.png" alt="Evaluation"/></p>

    <hr>
    <br />
    <p><span style="background-color: #f2f2f2; padding: 2px 4px; border-radius: 4px; font-weight: bold;">Paper</span>: 
        <a href="https://arxiv.org/abs/1907.08817">https://arxiv.org/abs/1907.08817</a></p>
   </div>
